
from typing import Dict, Any, List
import re

# Public API
def render_adverse_effects(st, drug_keys: List[str], db: Dict[str, Dict[str, Any]]):
    if not drug_keys:
        st.caption("ì„ íƒëœ í•­ì•”ì œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 1) ë¼ë²¨/í‚¤ ì •ë¦¬
    label_map = {k: db.get(k, {}).get("alias", k) for k in drug_keys}

    # 2) Ara-C ì œí˜• ë¼ë””ì˜¤ (í˜¼í•© í‘œê¸° ëª¨ë‘ ê°ì§€)
    def _is_arac_like(name: str) -> bool:
        s = (name or "").lower()
        return ("ara-c" in s) or ("cytarabine" in s) or ("ì‹œíƒ€ë¼ë¹ˆ" in s)

    def _arac_formulation_picker(st, db: Dict[str, Dict[str, Any]]):
        opts = []
        label_map2 = {"Ara-C IV":"ì •ë§¥(IV)","Ara-C SC":"í”¼í•˜(SC)","Ara-C HDAC":"ê³ ìš©ëŸ‰(HDAC)"}
        for key in ["Ara-C IV","Ara-C SC","Ara-C HDAC","Cytarabine IV","Cytarabine SC","Cytarabine HDAC"]:
            if key in db:
                opts.append(key if key.startswith("Ara-C") else key.replace("Cytarabine","Ara-C"))
        opts = sorted(set(opts))
        if not opts:
            return None
        return st.radio("Ara-C ì œí˜• ì„ íƒ", opts, format_func=lambda k: label_map2.get(k, k), key="arac_form_pick")

    # 3) ë Œë” ë£¨í”„
    for k in drug_keys:
        if _is_arac_like(k):
            pick = _arac_formulation_picker(st, db)
            if pick:
                k = pick

        rec = db.get(k, {})
        alias = rec.get("alias", k)
        st.write(f"- **{alias}**")

        # ìš”ì•½ AE
        ae = rec.get("ae", "")
        if ae and "ë¶€ì‘ìš© ì •ë³´ í•„ìš”" not in ae:
            st.caption(ae)
        else:
            st.caption("ìš”ì•½ ë¶€ì‘ìš© ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        # ëª¨ë‹ˆí„°ë§ ì¹©
        _render_monitoring_chips(st, rec)

        # ì‰¬ìš´ë§ ìƒì„¸
        _render_ae_detail(st, rec)

        # Cardio-Guard
        _render_cardio_guard(st, rec)

        st.divider()


def _render_monitoring_chips(st, rec: Dict[str, Any]):
    chips = []
    ae = rec.get("ae","")
    if any(x in ae for x in ["ê³¨ìˆ˜ì–µì œ","í˜¸ì¤‘êµ¬","í˜ˆì†ŒíŒ"]):
        chips.append("ğŸ©¸ CBC ì£¼ê¸° ì²´í¬")
    if any(x in ae for x in ["ê³ í˜ˆì••","ë‹¨ë°±ë‡¨"]):
        chips.append("ğŸ©º í˜ˆì••/ì†Œë³€ ë‹¨ë°± ëª¨ë‹ˆí„°")
    if any(x in ae for x in ["ê°„íš¨ì†Œ","ê°„ë…ì„±","í™©ë‹¬"]):
        chips.append("ğŸ§ª ê°„ê¸°ëŠ¥(LFT) ì¶”ì ")
    if any(x in ae for x in ["ì‹ ë…ì„±","í¬ë ˆì•„í‹°ë‹Œ","í˜ˆë‡¨"]):
        chips.append("ğŸ§ª ì‹ ê¸°ëŠ¥(Cr/eGFR) ì¶”ì ")
    if any(x in ae for x in ["ì„¤ì‚¬","ì˜¤ì‹¬","êµ¬í† "]):
        chips.append("ğŸ’§ íƒˆìˆ˜ ì£¼ì˜")
    if "QT" in ae or "QT " in ae:
        chips.append("ğŸ“ˆ ECG/QT ì²´í¬")

    if chips:
        st.markdown(" ".join([f"<span class='chip'>{c}</span>" for c in chips]), unsafe_allow_html=True)


def _render_ae_detail(st, rec: Dict[str, Any]):
    det = rec.get("ae_detail") if isinstance(rec, dict) else None
    if not isinstance(det, dict) or not det:
        return
    with st.expander("ğŸ” ìì„¸íˆ ë³´ê¸° (ì‰½ê²Œ ì„¤ëª…)", expanded=False):
        def bullet(title, items):
            if not items: return ""
            lis = "".join([f"<li>{x}</li>" for x in items])
            return f"<p><b>{title}</b></p><ul>{lis}</ul>"
        html = ""
        html += bullet("ìì£¼ ë‚˜íƒ€ë‚˜ëŠ” ì¦ìƒ", det.get("common"))
        html += bullet("ì¤‘ìš”í•œ ê²½ê³  ì‹ í˜¸", det.get("serious"))
        html += bullet("ê´€ë¦¬ íŒ", det.get("tips"))
        html += bullet("ë°”ë¡œ ì—°ë½í•´ì•¼ í•  ë•Œ", det.get("call"))
        if html:
            st.markdown(f"<div class='ae-detail'>{html}</div>", unsafe_allow_html=True)


def _render_cardio_guard(st, rec: Dict[str, Any]):
    name = (rec.get("alias") or "").lower()
    moa  = (rec.get("moa") or "").lower()
    def any_in(s, kws): 
        return any(k in s for k in kws)
    show_anthr = any_in(name, ["doxorubicin","daunorubicin","idarubicin"]) or "anthracycline" in moa
    show_her2  = any_in(name, ["trastuzumab","pertuzumab","t-dm1","deruxtecan"]) or "her2" in moa
    show_qt    = any_in(name, ["vandetanib","selpercatinib","pralsetinib","osimertinib","lapatinib","entrectinib"]) or ("qt" in (rec.get("ae","").lower()))
    show_arac  = any_in(name, ["ara-c hdac","cytarabine hdac"])

    if not (show_anthr or show_her2 or show_qt or show_arac):
        return

    bullets = []
    if show_anthr:
        bullets += [
            "ëˆ„ì  ìš©ëŸ‰ ì¶”ì (ë„ì˜¥ì†Œë£¨ë¹„ì‹  í™˜ì‚°) â€” 250â€“300mg/mÂ²: ê²½ê³„, 400â€“450mg/mÂ²: ê³ ìœ„í—˜",
            "LVEF: ê¸°ì € ë° 3ê°œì›” ê°„ê²©(ì„¼í„° í”„ë¡œí† ì½œ ìš°ì„ )",
            "LVEF <50% & 10%p ê°ì†Œ ë˜ëŠ” ì¦ìƒì„±: ì¼ì‹œì¤‘ë‹¨Â·í‰ê°€",
            "ì¦ìƒ: ìˆ¨ê°€ì¨Â·ì •ì¢Œí˜¸í¡Â·ì•¼ê°„í˜¸í¡ê³¤ë€Â·ë§ì´ˆë¶€ì¢…Â·ê°‘ì‘ìŠ¤ëŸ° ì²´ì¤‘â†‘ â†’ ì¦‰ì‹œ ìƒë‹´",
            "ê³ ìœ„í—˜êµ°(ì´ì „ í‰ë¶€ë°©ì‚¬ì„ , ì‹¬ì§ˆí™˜ ë“±): Dexrazoxane ê³ ë ¤"
        ]
    if show_her2:
        bullets += [
            "Trastuzumab ê³„ì—´: LVEF ê¸°ì € ë° ì£¼ê¸°ì (ë³´í†µ q3mo)",
            "LVEF ì €í•˜ ë˜ëŠ” ì‹¬ë¶€ì „ ì¦ìƒ ì‹œ ë³´ë¥˜Â·ì‹¬ì¥í‰ê°€"
        ]
    if show_qt:
        bullets += [
            "QT ì—°ì¥ ìœ„í—˜: ê¸°ì € ECG Â± ì¶”ì , Kâ‰¥4.0 / Mgâ‰¥2.0 ìœ ì§€",
            "ë™ì‹œ QT ì—°ì¥ ì•½ë¬¼Â·ì €ì¹¼ë¥¨í˜ˆì¦Â·ì €ë§ˆê·¸ë„¤ìŠ˜í˜ˆì¦ êµì •",
            "ì‹¤ì‹ Â·ì‹¬ê³„í•­ì§„Â·ì–´ì§€ëŸ¼ ë°œìƒ ì‹œ ì¦‰ì‹œ ì—°ë½"
        ]
    if show_arac:
        bullets += [
            "Ara-C ê³ ìš©ëŸ‰(HDAC) ë“œë¬¸ ì‹¬ë‚­ì—¼/ì‹¬ë‚­ì‚¼ì¶œ: í‰í†µÂ·í˜¸í¡ê³¤ë€ ì‹œ ì¦‰ì‹œ ë³´ê³ ",
            "ì¦ìƒ ì‹œ ECG/ì‹¬ì¥íš¨ì†Œ(Troponin) í‰ê°€ ê³ ë ¤"
        ]
    html = "<ul>" + "".join(f"<li>{b}</li>" for b in bullets) + "</ul>"
    st.markdown("<div class='cardio-guard'><div class='title'>â¤ï¸ Cardio-Guard</div>"+html+"</div>", unsafe_allow_html=True)

# === [PATCH:AE_GLOSSARY_KO+NORMALIZE] BEGIN ===
import re as _re_gls

_AE_GLOSSARY_KO = {
    "QT ì—°ì¥": "QT ê°„ê²©ì´ ì—°ì¥ë˜ë©´ ì‹¬ì¥ ë¦¬ë“¬ ì´ìƒì´ ë°œìƒí•  ìˆ˜ ìˆì–´ìš”. ì‹¤ì‹ ì´ë‚˜ ëŒì—°ì‚¬ ìœ„í—˜ì´ ìˆìœ¼ë‹ˆ ECG(ì‹¬ì „ë„) ì¶”ì  ê²€ì‚¬ê°€ ê¶Œì¥ë¼ìš”.",
    "RA ì¦í›„êµ°": "ë² ì‚¬ë…¸ì´ë“œ(íŠ¸ë ˆí‹°ë…¸ì¸) ì‚¬ìš© ì‹œ ê³ ì—´Â·í˜¸í¡ê³¤ë€Â·ì²´ì¤‘ ì¦ê°€ê°€ ë™ë°˜ë˜ë©´ RA ì¦í›„êµ°ì¼ ìˆ˜ ìˆì–´ìš”. ìŠ¤í…Œë¡œì´ë“œ ì¹˜ë£Œê°€ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‹ˆ ì¦‰ì‹œ ë³‘ì›ì— ì•Œë ¤ì•¼ í•´ìš”.",
    "ê³ ì‚¼íˆ¬ì¦í›„êµ°": "íƒˆìˆ˜ë‚˜ ì „í•´ì§ˆ ì´ìƒìœ¼ë¡œ ì˜ì‹ ì €í•˜Â·êµ¬í† ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆì–´ìš”. ì¶©ë¶„í•œ ìˆ˜ë¶„ ì„­ì·¨ê°€ í•„ìš”í•˜ë©° ì¦ìƒ ì‹œ ì¦‰ì‹œ ë‚´ì›í•˜ì„¸ìš”.",
    "ì‹ ê²½ë…ì„±": "ì†ë°œ ì €ë¦¼, ì‹œì•¼ í”ë“¤ë¦¼, ë³´í–‰ ë¶ˆì•ˆì • ë“±ì´ ë‚˜íƒ€ë‚˜ë©´ ì‹ ê²½ê³„ ì´ìƒì¼ ìˆ˜ ìˆì–´ìš”. ì‹¬í•´ì§€ê¸° ì „ ì£¼ì¹˜ì˜ì—ê²Œ ì•Œë ¤ì•¼ í•´ìš”.",
    "ì†ë°œì¦í›„êµ°": "ì†ë°”ë‹¥Â·ë°œë°”ë‹¥ì´ ë¶‰ì–´ì§€ê³  ë²—ê²¨ì§ˆ ìˆ˜ ìˆì–´ìš”. ë¯¸ì§€ê·¼í•œ ë¬¼ë¡œ ì”»ê³ , ë³´ìŠµì œë¥¼ ìì£¼ ë°”ë¥´ë©° ë§ˆì°°ì„ ì¤„ì´ì„¸ìš”.",
    "ê³¨ìˆ˜ì–µì œ": "ë°±í˜ˆêµ¬Â·í˜ˆì†ŒíŒì´ ê°ì†Œí•´ ê°ì—¼/ì¶œí˜ˆ ìœ„í—˜ì´ ì¦ê°€í•´ìš”. ë°œì—´(â‰¥38.5â„ƒ)Â·ì‰½ê²Œ ë©/ì½”í”¼ê°€ ë‚˜ë©´ ë°”ë¡œ ì—°ë½í•˜ì„¸ìš”.",
    "ê°„ë…ì„±": "AST/ALT ìƒìŠ¹, í™©ë‹¬Â·ì•”ìƒ‰ ì†Œë³€ì´ ìƒê¸°ë©´ ê°„ ì´ìƒ ì‹ í˜¸ì˜ˆìš”. ì•½ ì¤‘ë‹¨Â·ê²€ì‚¬ ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
    "ì‹ ì¥ë…ì„±": "ë¶€ì¢…Â·ì†Œë³€ ì¤„ì–´ë“¦Â·ê±°í’ˆë‡¨ê°€ ìˆìœ¼ë©´ ì‹ ì¥ ì´ìƒ ì‹ í˜¸ì˜ˆìš”. ìˆ˜ë¶„ ê´€ë¦¬ì™€ í˜ˆì•¡/ì†Œë³€ê²€ì‚¬ê°€ í•„ìš”í•´ìš”.",
    "ê´‘ê³¼ë¯¼": "í–‡ë¹›ì— ë…¸ì¶œë˜ë©´ ì‰½ê²Œ ë¹¨ê°œì§€ê±°ë‚˜ ë°œì§„ì´ ìƒê¸¸ ìˆ˜ ìˆì–´ìš”. SPF, ê¸´ì˜·, ìì™¸ì„  ì°¨ë‹¨ì´ ì¤‘ìš”í•´ìš”.",
    "êµ¬ë‚´ì—¼": "ì…ì•ˆ í†µì¦/ê¶¤ì–‘ìœ¼ë¡œ ì‹ì‚¬ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆì–´ìš”. ë¶€ë“œëŸ¬ìš´ ìŒì‹, ìê·¹ í”¼í•˜ê¸°, ì–¼ìŒì¡°ê°Â·ê°€ê¸€ì´ ë„ì›€ë¼ìš”.",
    "ì„¤ì‚¬": "ìˆ˜ì–‘ì„± ì„¤ì‚¬Â·íƒˆìˆ˜ ìœ„í—˜ì´ ìˆì–´ìš”. ë³´ì¶©ìˆ˜ë¶„(ORS)ì™€ í•„ìš” ì‹œ ì§€ì‚¬ì œ, ì‹¬í•˜ë©´ ë³‘ì›ì— ì—°ë½í•˜ì„¸ìš”.",
    "ë³€ë¹„": "ìˆ˜ë¶„Â·ì‹ì´ì„¬ìœ Â·ê°€ë²¼ìš´ ìš´ë™ì´ ë„ì›€ë¼ìš”. 3ì¼ ì´ìƒ ë³€ì´ ì—†ê±°ë‚˜ ë³µí†µÂ·êµ¬í†  ë™ë°˜ ì‹œ ì˜ì‚¬ì™€ ìƒì˜í•˜ì„¸ìš”.",
    "ì˜¤ì‹¬/êµ¬í† ": "ì†ŒëŸ‰ì”© ìì£¼ ì„­ì·¨í•˜ê³ , ì²˜ë°©ëœ í•­êµ¬í† ì œë¥¼ ê·œì¹™ì ìœ¼ë¡œ ë“œì„¸ìš”. íƒˆìˆ˜/êµ¬í†  ì§€ì† ì‹œ ì—°ë½í•˜ì„¸ìš”.",
    "íƒˆìˆ˜": "ì… ë§ˆë¦„, ì†Œë³€ëŸ‰ ê°ì†Œ, ì–´ì§€ëŸ¬ì›€ì€ íƒˆìˆ˜ ì‹ í˜¸ì˜ˆìš”. ìˆ˜ë¶„ ë³´ì¶©ì´ í•„ìš”í•˜ê³  ì‹¬í•˜ë©´ ë³‘ì›ìœ¼ë¡œ.",
    "ì €ë‚˜íŠ¸ë¥¨í˜ˆì¦": "ë‘í†µÂ·êµ¬ì—­Â·í˜¼ë™ì´ ìƒê¸¸ ìˆ˜ ìˆì–´ìš”. ê¸‰ê²©í•œ ì²´ì¤‘ ì¦ê°€(ë¶€ì¢…) ì‹œ ì¦‰ì‹œ ì—°ë½í•˜ì„¸ìš”.",
    "ê³ ì¹¼ë¥¨í˜ˆì¦": "ì‹¬ì¥ ë‘ê·¼ê±°ë¦¼Â·ê·¼ë ¥ ì €í•˜ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆì–´ìš”. ECGÂ·í˜ˆì•¡ê²€ì‚¬ê°€ í•„ìš”í•´ìš”.",
    "ì¶œí˜ˆ": "ì‡ëª¸/ì½”í”¼Â·ë©ì´ ì‰½ê²Œ ìƒê¸°ë©´ í˜ˆì†ŒíŒ ì €í•˜ ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”. ë„˜ì–´ì§Â·ìƒì²˜ë¥¼ ì£¼ì˜í•˜ê³  ë°”ë¡œ ì—°ë½í•˜ì„¸ìš”.",
    "í˜ˆì „": "í•œìª½ ë‹¤ë¦¬ ë¶“ê³  í†µì¦Â·í˜¸í¡ê³¤ë€Â·í‰í†µì€ í˜ˆì „ ì‹ í˜¸ì˜ˆìš”. ì¦‰ì‹œ ì‘ê¸‰í‰ê°€ê°€ í•„ìš”í•´ìš”.",
    "ë‹¨ë°±ë‡¨": "ê±°í’ˆë‡¨Â·ë¶€ì¢…ì´ ìˆìœ¼ë©´ ì‹ ì¥ ì†ìƒ ì‹ í˜¸ì˜ˆìš”. ì†Œë³€ê²€ì‚¬ ì¶”ì ì´ í•„ìš”í•´ìš”.",
    "ê³ í˜ˆì••": "ë‘í†µÂ·ì–´ì§€ëŸ¬ì›€ì´ ìˆìœ¼ë©´ í˜ˆì••ì„ í™•ì¸í•˜ì„¸ìš”. ëª©í‘œì¹˜ë¥¼ ë„˜ì–´ê°€ë©´ ì•½ ì¡°ì ˆì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
    "ìƒì²˜ì¹˜ìœ  ì§€ì—°": "ìˆ˜ìˆ /ìƒì²˜ê°€ ì˜ ë‚«ì§€ ì•Šì„ ìˆ˜ ìˆì–´ìš”. ì¹˜ë£Œ ì „í›„ ì¼ì • ì¡°ì •ì´ í•„ìš”í•˜ë‹ˆ ì˜ë£Œì§„ê³¼ ìƒì˜í•˜ì„¸ìš”.",
    "íë…ì„±": "ê¸°ì¹¨Â·í˜¸í¡ê³¤ë€ ì•…í™”ëŠ” í ì´ìƒ ì‹ í˜¸ì˜ˆìš”. í‰ë¶€ ì˜ìƒÂ·í˜¸í¡ê¸° í‰ê°€ê°€ í•„ìš”í•´ìš”.",
    "ê°„ì§ˆì„± íì§ˆí™˜": "í˜¸í¡ê³¤ë€/ê±´ì„± ê¸°ì¹¨Â·ë°œì—´ì´ ë™ë°˜ë˜ë©´ ì˜ì‹¬ë¼ìš”. ì•½ ì¤‘ë‹¨ê³¼ ìŠ¤í…Œë¡œì´ë“œê°€ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
}

_AE_SYNONYMS = {
    "qt prolongation": "QT ì—°ì¥",
    "qt interval prolongation": "QT ì—°ì¥",
    "torsades": "QT ì—°ì¥",
    "ra syndrome": "RA ì¦í›„êµ°",
    "retinoic acid syndrome": "RA ì¦í›„êµ°",
    "hand-foot syndrome": "ì†ë°œì¦í›„êµ°",
    "palmar-plantar erythrodysesthesia": "ì†ë°œì¦í›„êµ°",
    "neurotoxicity": "ì‹ ê²½ë…ì„±",
    "peripheral neuropathy": "ì‹ ê²½ë…ì„±",
    "stomatitis": "êµ¬ë‚´ì—¼",
    "mucositis": "êµ¬ë‚´ì—¼",
    "hepatic toxicity": "ê°„ë…ì„±",
    "renal toxicity": "ì‹ ì¥ë…ì„±",
    "photosensitivity": "ê´‘ê³¼ë¯¼",
}

def _norm_ae_term(s: str) -> str:
    if not s:
        return ""
    x = s.strip()
    x = _re_gls.sub(r"\(.*?\)|\[.*?\]", "", x)
    x = _re_gls.sub(r"[Â·,:;/]+", " ", x)
    x = _re_gls.sub(r"\s+", " ", x).strip()
    return x

def _to_glossary_key(term: str):
    if not term:
        return None
    t = _norm_ae_term(term)
    if t in _AE_GLOSSARY_KO:
        return t
    low = t.lower()
    if low in _AE_SYNONYMS:
        k = _AE_SYNONYMS[low]
        if k in _AE_GLOSSARY_KO:
            return k
    for k in _AE_GLOSSARY_KO.keys():
        if k in t:
            return k
    return None

def _ae_explain(term: str):
    key = _to_glossary_key(term)
    return _AE_GLOSSARY_KO.get(key) if key else None

def _augment_terms_with_explain(terms):
    out = []
    for t in terms or []:
        exp = _ae_explain(t)
        label = _norm_ae_term(t)
        out.append(f"{label} â€” {exp}" if exp else label)
    return out
# === [PATCH:AE_GLOSSARY_KO+NORMALIZE] END ===

# === [PATCH:AE_GLOSSARY_OVERRIDE_BUILD] BEGIN ===
def build_ae_summary_md(drug_list, formulation_map=None):
    try:
        ae = _bm_get_ae_detail_map()
    except Exception:
        ae = {}
    lines = ["## í•­ì•”ì œ ìš”ì•½ (ì˜/í•œ + ë¶€ì‘ìš©)"]
    if not drug_list:
        lines.append("- (ì„ íƒëœ í•­ì•”ì œê°€ ì—†ìŠµë‹ˆë‹¤)")
        return "\n".join(lines)
    for d in drug_list:
        info = (ae or {}).get(d)
        if not info:
            lines.append(f"### {d}")
            lines.append("- ìƒì„¸ ì •ë³´ ì¤€ë¹„ ì¤‘")
            lines.append("")
            continue
        title = info.get("title", d)
        lines.append(f"### {title}")
        forms = info.get("formulations") or {}
        sel_form = (formulation_map or {}).get(d) if formulation_map else None
        if forms:
            if sel_form and sel_form in forms:
                lines.append(f"- **ì œí˜•({sel_form})**: " + " Â· ".join(_augment_terms_with_explain(forms[sel_form])))
            else:
                for fk, fv in forms.items():
                    lines.append(f"- **ì œí˜•({fk})**: " + " Â· ".join(_augment_terms_with_explain(fv)))
        common  = info.get("common") or []
        serious = info.get("serious") or []
        call    = info.get("call") or []
        if common:
            lines.append("- **ì¼ë°˜**: " + " Â· ".join(_augment_terms_with_explain(common)))
        if serious:
            lines.append("- **ì¤‘ì¦**: " + " Â· ".join(_augment_terms_with_explain(serious)))
        if call:
            lines.append("- **ì—°ë½ í•„ìš”**: " + " Â· ".join(_augment_terms_with_explain(call)))
        lines.append("")
    return "\n".join(lines)
# === [PATCH:AE_GLOSSARY_OVERRIDE_BUILD] END ===


# === [INTEGRATED: AE GLOSSARY + NORMALIZER + TKIs + BUILD/RENDER] BEGIN ===
# 1) Glossary (Korean) + synonyms + normalizer
import re as _re_gls

_AE_GLOSSARY_KO = {
    "QT ì—°ì¥": "QT ê°„ê²©ì´ ì—°ì¥ë˜ë©´ ì‹¬ì¥ ë¦¬ë“¬ ì´ìƒì´ ë°œìƒí•  ìˆ˜ ìˆì–´ìš”. ì‹¤ì‹ ì´ë‚˜ ëŒì—°ì‚¬ ìœ„í—˜ì´ ìˆìœ¼ë‹ˆ ECG(ì‹¬ì „ë„) ì¶”ì  ê²€ì‚¬ê°€ ê¶Œì¥ë¼ìš”.",
    "RA ì¦í›„êµ°": "ë² ì‚¬ë…¸ì´ë“œ(íŠ¸ë ˆí‹°ë…¸ì¸) ì‚¬ìš© ì‹œ ê³ ì—´Â·í˜¸í¡ê³¤ë€Â·ì²´ì¤‘ ì¦ê°€ê°€ ë™ë°˜ë˜ë©´ RA ì¦í›„êµ°ì¼ ìˆ˜ ìˆì–´ìš”. ìŠ¤í…Œë¡œì´ë“œ ì¹˜ë£Œê°€ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‹ˆ ì¦‰ì‹œ ë³‘ì›ì— ì•Œë ¤ì•¼ í•´ìš”.",
    "ê³ ì‚¼íˆ¬ì¦í›„êµ°": "íƒˆìˆ˜ë‚˜ ì „í•´ì§ˆ ì´ìƒìœ¼ë¡œ ì˜ì‹ ì €í•˜Â·êµ¬í† ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆì–´ìš”. ì¶©ë¶„í•œ ìˆ˜ë¶„ ì„­ì·¨ê°€ í•„ìš”í•˜ë©° ì¦ìƒ ì‹œ ì¦‰ì‹œ ë‚´ì›í•˜ì„¸ìš”.",
    "ì‹ ê²½ë…ì„±": "ì†ë°œ ì €ë¦¼, ì‹œì•¼ í”ë“¤ë¦¼, ë³´í–‰ ë¶ˆì•ˆì • ë“±ì´ ë‚˜íƒ€ë‚˜ë©´ ì‹ ê²½ê³„ ì´ìƒì¼ ìˆ˜ ìˆì–´ìš”. ì‹¬í•´ì§€ê¸° ì „ ì£¼ì¹˜ì˜ì—ê²Œ ì•Œë ¤ì•¼ í•´ìš”.",
    "ì†ë°œì¦í›„êµ°": "ì†ë°”ë‹¥Â·ë°œë°”ë‹¥ì´ ë¶‰ì–´ì§€ê³  ë²—ê²¨ì§ˆ ìˆ˜ ìˆì–´ìš”. ë¯¸ì§€ê·¼í•œ ë¬¼ë¡œ ì”»ê³ , ë³´ìŠµì œë¥¼ ìì£¼ ë°”ë¥´ë©° ë§ˆì°°ì„ ì¤„ì´ì„¸ìš”.",
    "ê³¨ìˆ˜ì–µì œ": "ë°±í˜ˆêµ¬Â·í˜ˆì†ŒíŒì´ ê°ì†Œí•´ ê°ì—¼/ì¶œí˜ˆ ìœ„í—˜ì´ ì¦ê°€í•´ìš”. ë°œì—´(â‰¥38.5â„ƒ)Â·ì‰½ê²Œ ë©/ì½”í”¼ê°€ ë‚˜ë©´ ë°”ë¡œ ì—°ë½í•˜ì„¸ìš”.",
    "ê°„ë…ì„±": "AST/ALT ìƒìŠ¹, í™©ë‹¬Â·ì•”ìƒ‰ ì†Œë³€ì´ ìƒê¸°ë©´ ê°„ ì´ìƒ ì‹ í˜¸ì˜ˆìš”. ì•½ ì¤‘ë‹¨Â·ê²€ì‚¬ ì¡°ì •ì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
    "ì‹ ì¥ë…ì„±": "ë¶€ì¢…Â·ì†Œë³€ ì¤„ì–´ë“¦Â·ê±°í’ˆë‡¨ê°€ ìˆìœ¼ë©´ ì‹ ì¥ ì´ìƒ ì‹ í˜¸ì˜ˆìš”. ìˆ˜ë¶„ ê´€ë¦¬ì™€ í˜ˆì•¡/ì†Œë³€ê²€ì‚¬ê°€ í•„ìš”í•´ìš”.",
    "ê´‘ê³¼ë¯¼": "í–‡ë¹›ì— ë…¸ì¶œë˜ë©´ ì‰½ê²Œ ë¹¨ê°œì§€ê±°ë‚˜ ë°œì§„ì´ ìƒê¸¸ ìˆ˜ ìˆì–´ìš”. SPF, ê¸´ì˜·, ìì™¸ì„  ì°¨ë‹¨ì´ ì¤‘ìš”í•´ìš”.",
    "êµ¬ë‚´ì—¼": "ì…ì•ˆ í†µì¦/ê¶¤ì–‘ìœ¼ë¡œ ì‹ì‚¬ê°€ ì–´ë ¤ìš¸ ìˆ˜ ìˆì–´ìš”. ë¶€ë“œëŸ¬ìš´ ìŒì‹, ìê·¹ í”¼í•˜ê¸°, ì–¼ìŒì¡°ê°Â·ê°€ê¸€ì´ ë„ì›€ë¼ìš”.",
    "ì„¤ì‚¬": "ìˆ˜ì–‘ì„± ì„¤ì‚¬Â·íƒˆìˆ˜ ìœ„í—˜ì´ ìˆì–´ìš”. ë³´ì¶©ìˆ˜ë¶„(ORS)ì™€ í•„ìš” ì‹œ ì§€ì‚¬ì œ, ì‹¬í•˜ë©´ ë³‘ì›ì— ì—°ë½í•˜ì„¸ìš”.",
    "ë³€ë¹„": "ìˆ˜ë¶„Â·ì‹ì´ì„¬ìœ Â·ê°€ë²¼ìš´ ìš´ë™ì´ ë„ì›€ë¼ìš”. 3ì¼ ì´ìƒ ë³€ì´ ì—†ê±°ë‚˜ ë³µí†µÂ·êµ¬í†  ë™ë°˜ ì‹œ ì˜ì‚¬ì™€ ìƒì˜í•˜ì„¸ìš”.",
    "ì˜¤ì‹¬/êµ¬í† ": "ì†ŒëŸ‰ì”© ìì£¼ ì„­ì·¨í•˜ê³ , ì²˜ë°©ëœ í•­êµ¬í† ì œë¥¼ ê·œì¹™ì ìœ¼ë¡œ ë“œì„¸ìš”. íƒˆìˆ˜/êµ¬í†  ì§€ì† ì‹œ ì—°ë½í•˜ì„¸ìš”.",
    "íƒˆìˆ˜": "ì… ë§ˆë¦„, ì†Œë³€ëŸ‰ ê°ì†Œ, ì–´ì§€ëŸ¬ì›€ì€ íƒˆìˆ˜ ì‹ í˜¸ì˜ˆìš”. ìˆ˜ë¶„ ë³´ì¶©ì´ í•„ìš”í•˜ê³  ì‹¬í•˜ë©´ ë³‘ì›ìœ¼ë¡œ.",
    "ì €ë‚˜íŠ¸ë¥¨í˜ˆì¦": "ë‘í†µÂ·êµ¬ì—­Â·í˜¼ë™ì´ ìƒê¸¸ ìˆ˜ ìˆì–´ìš”. ê¸‰ê²©í•œ ì²´ì¤‘ ì¦ê°€(ë¶€ì¢…) ì‹œ ì¦‰ì‹œ ì—°ë½í•˜ì„¸ìš”.",
    "ê³ ì¹¼ë¥¨í˜ˆì¦": "ì‹¬ì¥ ë‘ê·¼ê±°ë¦¼Â·ê·¼ë ¥ ì €í•˜ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆì–´ìš”. ECGÂ·í˜ˆì•¡ê²€ì‚¬ê°€ í•„ìš”í•´ìš”.",
    "ì¶œí˜ˆ": "ì‡ëª¸/ì½”í”¼Â·ë©ì´ ì‰½ê²Œ ìƒê¸°ë©´ í˜ˆì†ŒíŒ ì €í•˜ ê°€ëŠ¥ì„±ì´ ìˆì–´ìš”. ë„˜ì–´ì§Â·ìƒì²˜ë¥¼ ì£¼ì˜í•˜ê³  ë°”ë¡œ ì—°ë½í•˜ì„¸ìš”.",
    "í˜ˆì „": "í•œìª½ ë‹¤ë¦¬ ë¶“ê³  í†µì¦Â·í˜¸í¡ê³¤ë€Â·í‰í†µì€ í˜ˆì „ ì‹ í˜¸ì˜ˆìš”. ì¦‰ì‹œ ì‘ê¸‰í‰ê°€ê°€ í•„ìš”í•´ìš”.",
    "ë‹¨ë°±ë‡¨": "ê±°í’ˆë‡¨Â·ë¶€ì¢…ì´ ìˆìœ¼ë©´ ì‹ ì¥ ì†ìƒ ì‹ í˜¸ì˜ˆìš”. ì†Œë³€ê²€ì‚¬ ì¶”ì ì´ í•„ìš”í•´ìš”.",
    "ê³ í˜ˆì••": "ë‘í†µÂ·ì–´ì§€ëŸ¬ì›€ì´ ìˆìœ¼ë©´ í˜ˆì••ì„ í™•ì¸í•˜ì„¸ìš”. ëª©í‘œì¹˜ë¥¼ ë„˜ì–´ê°€ë©´ ì•½ ì¡°ì ˆì´ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
    "ìƒì²˜ì¹˜ìœ  ì§€ì—°": "ìˆ˜ìˆ /ìƒì²˜ê°€ ì˜ ë‚«ì§€ ì•Šì„ ìˆ˜ ìˆì–´ìš”. ì¹˜ë£Œ ì „í›„ ì¼ì • ì¡°ì •ì´ í•„ìš”í•˜ë‹ˆ ì˜ë£Œì§„ê³¼ ìƒì˜í•˜ì„¸ìš”.",
    "íë…ì„±": "ê¸°ì¹¨Â·í˜¸í¡ê³¤ë€ ì•…í™”ëŠ” í ì´ìƒ ì‹ í˜¸ì˜ˆìš”. í‰ë¶€ ì˜ìƒÂ·í˜¸í¡ê¸° í‰ê°€ê°€ í•„ìš”í•´ìš”.",
    "ê°„ì§ˆì„± íì§ˆí™˜": "í˜¸í¡ê³¤ë€/ê±´ì„± ê¸°ì¹¨Â·ë°œì—´ì´ ë™ë°˜ë˜ë©´ ì˜ì‹¬ë¼ìš”. ì•½ ì¤‘ë‹¨ê³¼ ìŠ¤í…Œë¡œì´ë“œê°€ í•„ìš”í•  ìˆ˜ ìˆì–´ìš”.",
}

_AE_SYNONYMS = {
    "qt prolongation": "QT ì—°ì¥",
    "qt interval prolongation": "QT ì—°ì¥",
    "torsades": "QT ì—°ì¥",
    "ra syndrome": "RA ì¦í›„êµ°",
    "retinoic acid syndrome": "RA ì¦í›„êµ°",
    "hand-foot syndrome": "ì†ë°œì¦í›„êµ°",
    "palmar-plantar erythrodysesthesia": "ì†ë°œì¦í›„êµ°",
    "neurotoxicity": "ì‹ ê²½ë…ì„±",
    "peripheral neuropathy": "ì‹ ê²½ë…ì„±",
    "stomatitis": "êµ¬ë‚´ì—¼",
    "mucositis": "êµ¬ë‚´ì—¼",
    "hepatic toxicity": "ê°„ë…ì„±",
    "renal toxicity": "ì‹ ì¥ë…ì„±",
    "photosensitivity": "ê´‘ê³¼ë¯¼",
}

def _norm_ae_term(s: str) -> str:
    if not s:
        return ""
    x = s.strip()
    x = _re_gls.sub(r"\(.*?\)|\[.*?\]", "", x)
    x = _re_gls.sub(r"[Â·,:;/]+", " ", x)
    x = _re_gls.sub(r"\s+", " ", x).strip()
    return x

def _to_glossary_key(term: str):
    if not term:
        return None
    t = _norm_ae_term(term)
    if t in _AE_GLOSSARY_KO:
        return t
    low = t.lower()
    if low in _AE_SYNONYMS:
        k = _AE_SYNONYMS[low]
        if k in _AE_GLOSSARY_KO:
            return k
    for k in _AE_GLOSSARY_KO.keys():
        if k in t:
            return k
    return None

def _ae_explain(term: str):
    key = _to_glossary_key(term)
    return _AE_GLOSSARY_KO.get(key) if key else None

def _augment_terms_with_explain(terms):
    out = []
    for t in terms or []:
        exp = _ae_explain(t)
        label = _norm_ae_term(t)
        out.append(f"{label} â€” {exp}" if exp else label)
    return out

# 2) Extend AE map for GIST TKIs
def _bm_extend_gist_tkis(ae_map: dict):
    ae_map.update({
        "Imatinib": {
            "title": "Imatinib (ì´ë§¤í‹°ë‹™)",
            "common": ["ë¶€ì¢…", "ì˜¤ì‹¬/êµ¬í† ", "ì„¤ì‚¬", "êµ¬ë‚´ì—¼", "ê·¼ìœ¡ê²½ë ¨/í†µì¦", "ë°œì§„", "ê³¨ìˆ˜ì–µì œ"],
            "serious": ["ê°„ë…ì„±", "ì‹¬ë¶€ì „(ë“œë¬¾)", "ì‹¬í•œ ì²´ì•¡ì €ë¥˜(í‰ìˆ˜/ë³µìˆ˜)"],
            "call": ["ê°‘ì‘ìŠ¤ëŸ° ì²´ì¤‘ ì¦ê°€/í˜¸í¡ê³¤ë€", "í™©ë‹¬/ì•”ìƒ‰ ì†Œë³€", "38.5â„ƒ ì´ìƒ ë°œì—´ ë˜ëŠ” ì¶œí˜ˆ"]
        },
        "Sunitinib": {
            "title": "Sunitinib (ìˆ˜ë‹ˆí‹°ë‹™)",
            "common": ["í”¼ë¡œ", "ì„¤ì‚¬", "êµ¬ë‚´ì—¼", "ì†ë°œì¦í›„êµ°", "ê³ í˜ˆì••", "ê°‘ìƒì„  ê¸°ëŠ¥ì €í•˜"],
            "serious": ["ì‹¬ê¸°ëŠ¥ ì €í•˜", "QT ì—°ì¥", "ê°„ë…ì„±", "ì¶œí˜ˆ"],
            "call": ["í‰í†µ/ì‹¤ì‹ /ì‹¬í•œ ì–´ì§€ëŸ¬ì›€", "ê²€ì€ ë³€/í† í˜ˆ", "í™©ë‹¬/ì•”ìƒ‰ ì†Œë³€", "ì‹¬í•œ ì†ë°œì¦í›„êµ°"]
        },
        "Regorafenib": {
            "title": "Regorafenib (ë ˆê³ ë¼í˜ë‹™)",
            "common": ["ì†ë°œì¦í›„êµ°", "ê³ í˜ˆì••", "í”¼ë¡œ", "ì„¤ì‚¬", "êµ¬ë‚´ì—¼"],
            "serious": ["ê°„ë…ì„±(ì¤‘ìš”)", "ì¶œí˜ˆ", "ìœ„ì¥ê´€ ì²œê³µ", "QT ì—°ì¥(ê°€ëŠ¥)"],
            "call": ["í™©ë‹¬/ì•”ìƒ‰ ì†Œë³€", "ì‹¬í•œ ë³µí†µ/ë°œì—´", "ì§€ì†ì  ë¹„ì¶œí˜ˆÂ·í˜ˆë³€", "í‰í†µ/ì‹¤ì‹ "]
        },
        "Ripretinib": {
            "title": "Ripretinib (ë¦¬í”„ë ˆí‹°ë‹™)",
            "common": ["íƒˆëª¨", "ì†ë°œì¦í›„êµ°", "ê·¼ìœ¡í†µ", "í”¼ë¡œ", "ê³ í˜ˆì••"],
            "serious": ["ì‹¬ê¸°ëŠ¥ ì´ìƒ", "í”¼ë¶€ì•”(ë“œë¬¾)", "QT ì—°ì¥(ê°€ëŠ¥)"],
            "call": ["í‰í†µ/í˜¸í¡ê³¤ë€/ì‹¤ì‹ ", "ì‹¬í•œ ì†ë°œì¦í›„êµ°", "ìƒˆë¡œìš´ í”¼ë¶€ ë³‘ë³€/ì¶œí˜ˆì„± ë³‘ë³€"]
        },
    })
    return ae_map

def _bm_get_ae_detail_map_safe():
    try:
        base = _bm_get_ae_detail_map()
    except Exception:
        base = {}
    try:
        base = dict(base)
    except Exception:
        base = {}
    return _bm_extend_gist_tkis(base)

# 3) Build MD using augmented map and explanations
def build_ae_summary_md(drug_list, formulation_map=None):
    ae = _bm_get_ae_detail_map_safe()
    lines = ["## í•­ì•”ì œ ìš”ì•½ (ì˜/í•œ + ë¶€ì‘ìš©)"]
    if not drug_list:
        lines.append("- (ì„ íƒëœ í•­ì•”ì œê°€ ì—†ìŠµë‹ˆë‹¤)")
        return "\\n".join(lines)
    for d in drug_list:
        info = ae.get(d)
        if not info:
            lines.append(f"### {d}")
            lines.append("- ìƒì„¸ ì •ë³´ ì¤€ë¹„ ì¤‘")
            lines.append("")
            continue
        title = info.get("title", d)
        lines.append(f"### {title}")
        forms = info.get("formulations") or {}
        sel_form = (formulation_map or {}).get(d) if formulation_map else None
        if forms:
            if sel_form and sel_form in forms:
                lines.append(f"- **ì œí˜•({sel_form})**: " + " Â· ".join(_augment_terms_with_explain(forms[sel_form])))
            else:
                for fk, fv in forms.items():
                    lines.append(f"- **ì œí˜•({fk})**: " + " Â· ".join(_augment_terms_with_explain(fv)))
        common  = info.get("common") or []
        serious = info.get("serious") or []
        call    = info.get("call") or []
        if common:
            lines.append("- **ì¼ë°˜**: " + " Â· ".join(_augment_terms_with_explain(common)))
        if serious:
            lines.append("- **ì¤‘ì¦**: " + " Â· ".join(_augment_terms_with_explain(serious)))
        if call:
            lines.append("- **ì—°ë½ í•„ìš”**: " + " Â· ".join(_augment_terms_with_explain(call)))
        lines.append("")
    return "\\n".join(lines)

# 4) Post-process: append glossary notes by scanning the final md once
def append_glossary_notes(md_text: str) -> str:
    try:
        glossary = _AE_GLOSSARY_KO
    except Exception:
        return md_text
    if not md_text or not glossary:
        return md_text
    found = []
    body = md_text
    for k, v in glossary.items():
        if k and (k in body):
            found.append((k, v))
    if not found:
        return md_text
    uniq, seen = [], set()
    for k, v in found:
        if k not in seen:
            uniq.append((k, v)); seen.add(k)
    lines = ["", "### ìš©ì–´ í’€ì´"]
    for k, v in uniq:
        lines.append(f"- **{k}**: {v}")
    joiner = "\\n\\n" if not md_text.endswith("\\n") else "\\n"
    return md_text + joiner + "\\n".join(lines) + "\\n"

# 5) Safe renderer (used by app import alias)
def render_ae_detail(drug_list, formulation_map=None):
    md = build_ae_summary_md(drug_list, formulation_map=formulation_map)
    try:
        import streamlit as st
        st.markdown(md)
    except Exception:
        # headless usage
        return md
    return md
# === [INTEGRATED: AE GLOSSARY + NORMALIZER + TKIs + BUILD/RENDER] END ===


# === [PATCH:AE_GLOSSARY_CONCISE_MODE] BEGIN ===
# í™˜ì ì¹œí™” ì„¤ëª…ì„ 'ì§§ê²Œ' ì¶œë ¥í•˜ê¸° ìœ„í•œ ëª¨ë“œ/ì‚¬ì „/í—¬í¼
_AE_EXPLAIN_MODE = "short"  # "short" | "full"

# ìì£¼ ì“°ëŠ” í•­ëª©ì€ ì´ˆê°„ê²° ë²„ì „ ì œê³µ
_AE_GLOSSARY_KO_SHORT = {
    "QT ì—°ì¥": "ì‹¤ì‹ Â·ëŒì—°ì‚¬ ìœ„í—˜ â†‘ â†’ ECG ì¶”ì .",
    "RA ì¦í›„êµ°": "ê³ ì—´Â·í˜¸í¡ê³¤ë€Â·ì²´ì¤‘â†‘ â†’ ì¦‰ì‹œ ë³‘ì›, ìŠ¤í…Œë¡œì´ë“œ í•„ìš” ê°€ëŠ¥.",
    "ê³ ì‚¼íˆ¬ì¦í›„êµ°": "íƒˆìˆ˜Â·ì „í•´ì§ˆ ì´ìƒ â†’ ìˆ˜ë¶„ ë³´ì¶©, ì˜ì‹ ì €í•˜/êµ¬í†  ì‹œ ë‚´ì›.",
    "ì‹ ê²½ë…ì„±": "ì €ë¦¼Â·ì‹œì•¼í”ë“¤ë¦¼Â·ë³´í–‰ë¶ˆì•ˆì • â†’ ì¦ìƒ ì•…í™” ì „ ì—°ë½.",
    "ì†ë°œì¦í›„êµ°": "ì†ë°œ ë¶‰ì–´ì§Â·ë²—ê²¨ì§ â†’ ë³´ìŠµÂ·ë§ˆì°° ì¤„ì´ê¸°.",
    "ê³¨ìˆ˜ì–µì œ": "ê°ì—¼Â·ì¶œí˜ˆ ìœ„í—˜ â†‘ â†’ 38.5â„ƒâ†‘Â·ì¶œí˜ˆ ì‹œ ì¦‰ì‹œ ì—°ë½.",
    "ê°„ë…ì„±": "í™©ë‹¬Â·ì•”ìƒ‰ ì†Œë³€ â†’ ì•½ ì¡°ì • í•„ìš”, ì¦‰ì‹œ ì—°ë½.",
    "ì‹ ì¥ë…ì„±": "ë¶€ì¢…Â·ì†Œë³€ê°ì†ŒÂ·ê±°í’ˆë‡¨ â†’ ê²€ì‚¬/ìˆ˜ë¶„ê´€ë¦¬, ì•…í™” ì‹œ ë‚´ì›.",
    "ê´‘ê³¼ë¯¼": "í–‡ë¹› ë¯¼ê° â†‘ â†’ ìì™¸ì„  ì°¨ë‹¨Â·ê¸´ ì˜·.",
    "êµ¬ë‚´ì—¼": "ì…í†µì¦/ê¶¤ì–‘ â†’ ìê·¹ í”¼í•˜ê³  ê°€ê¸€.",
    "ì„¤ì‚¬": "íƒˆìˆ˜ ìœ„í—˜ â†’ ORS, ì§€ì† ì‹œ ì—°ë½.",
    "ë³€ë¹„": "ìˆ˜ë¶„Â·ì„¬ìœ Â·ìš´ë™, 3ì¼â†‘/ë³µí†µÂ·êµ¬í†  ë™ë°˜ ì‹œ ì—°ë½.",
    "ì˜¤ì‹¬/êµ¬í† ": "ì†ŒëŸ‰ì”© ìì£¼, í•­êµ¬í† ì œ ê·œì¹™ ë³µìš©.",
    "íƒˆìˆ˜": "ì…ë§ˆë¦„Â·ì–´ì§€ëŸ¼ â†’ ìˆ˜ë¶„ ë³´ì¶©, ì‹¬í•˜ë©´ ë‚´ì›.",
    "ì €ë‚˜íŠ¸ë¥¨í˜ˆì¦": "ë‘í†µÂ·í˜¼ë™Â·ë¶€ì¢… â†’ ì¦‰ì‹œ í‰ê°€.",
    "ê³ ì¹¼ë¥¨í˜ˆì¦": "ë‘ê·¼ê±°ë¦¼Â·ê·¼ë ¥ì €í•˜ â†’ ECG/í˜ˆì•¡ê²€ì‚¬.",
    "ì¶œí˜ˆ": "ì‡ëª¸/ì½”í”¼Â·ë©â†‘ â†’ ì™¸ìƒ ì£¼ì˜Â·ì¦‰ì‹œ ì—°ë½.",
    "í˜ˆì „": "í¸ì¸¡ ë‹¤ë¦¬ ë¶€ì¢…Â·í‰í†µ/í˜¸í¡ê³¤ë€ â†’ ì‘ê¸‰í‰ê°€.",
    "ë‹¨ë°±ë‡¨": "ê±°í’ˆë‡¨Â·ë¶€ì¢… â†’ ì†Œë³€ì¶”ì .",
    "ê³ í˜ˆì••": "ë‘í†µÂ·ì–´ì§€ëŸ¼ â†’ í˜ˆì•• ì²´í¬Â·ì•½ ì¡°ì ˆ.",
    "ìƒì²˜ì¹˜ìœ  ì§€ì—°": "ìˆ˜ìˆ /ìƒì²˜ íšŒë³µ ì§€ì—° â†’ ì¼ì • ìƒì˜.",
    "íë…ì„±": "ê¸°ì¹¨Â·í˜¸í¡ê³¤ë€ ì•…í™” â†’ í‰ë¶€ í‰ê°€.",
    "ê°„ì§ˆì„± íì§ˆí™˜": "í˜¸í¡ê³¤ë€/ê¸°ì¹¨Â·ë°œì—´ â†’ ì•½ ì¤‘ë‹¨Â·ìŠ¤í…Œë¡œì´ë“œ ê³ ë ¤.",
}

def _brief_text(txt: str, max_chars: int = 80) -> str:
    if not txt:
        return ""
    s = txt.strip()
    # ì²« ë¬¸ì¥ë§Œ ì¶”ì¶œ(., !, ? ê¸°ì¤€) í›„ ê¸¸ì´ ì œí•œ
    cut_pos = len(s)
    for p in [". ", ".\n", "!", "?", "ï¼", "ï¼Ÿ"]:
        i = s.find(p)
        if i != -1:
            cut_pos = min(cut_pos, i + len(p.strip()))
    s = s[:cut_pos].strip()
    if len(s) > max_chars:
        s = s[:max_chars-1].rstrip() + "â€¦"
    return s

def _get_explain(term: str, mode: str = None) -> str | None:
    """ìš©ì–´ ì„¤ëª…ì„ ëª¨ë“œì— ë§ê²Œ ë°˜í™˜."""
    if term is None:
        return None
    mode = (mode or _AE_EXPLAIN_MODE).lower()
    # í‘œì¤€ í‚¤ ì–»ê¸°
    key = _to_glossary_key(term)
    if not key:
        return None
    full = _AE_GLOSSARY_KO.get(key)
    if mode == "full":
        return full
    # short ëª¨ë“œ
    short = _AE_GLOSSARY_KO_SHORT.get(key)
    if short:
        return short
    return _brief_text(full)

# ê¸°ì¡´ í—¬í¼ë¥¼ 'ì§§ê²Œ' ì¶œë ¥í•˜ë„ë¡ êµì²´
def _augment_terms_with_explain(terms):
    out = []
    for t in (terms or []):
        exp = _get_explain(t, "short")
        label = _norm_ae_term(t)
        out.append(f"{label} â€” {exp}" if exp else label)
    return out

# ìš©ì–´í’€ì´ ì„¹ì…˜ë„ ì§§ê²Œ
def append_glossary_notes(md_text: str) -> str:
    try:
        glossary = _AE_GLOSSARY_KO
    except Exception:
        return md_text
    if not md_text or not glossary:
        return md_text
    found = []
    body = md_text
    for k in glossary.keys():
        if k and (k in body):
            exp = _get_explain(k, "short")
            if exp:
                found.append((k, exp))
    if not found:
        return md_text
    uniq, seen = [], set()
    for k, v in found:
        if k not in seen:
            uniq.append((k, v)); seen.add(k)
    lines = ["", "### ìš©ì–´ í’€ì´(ìš”ì•½)"]
    for k, v in uniq:
        lines.append(f"- **{k}**: {v}")
    joiner = "\\n\\n" if not md_text.endswith("\\n") else "\\n"
    return md_text + joiner + "\\n".join(lines) + "\\n"
# === [PATCH:AE_GLOSSARY_CONCISE_MODE] END ===


# === [PATCH:AE_GLOSSARY_TRIGGERED] BEGIN ===
# ì„¤ëª…ì€ 'ë“±ì¥í–ˆì„ ë•Œë§Œ' ë¶™ì´ëŠ” ëª¨ë“œ
_AE_GLOSSARY_TRIGGER_MODE = "presence_only"  # "presence_only" | "always"

# í‚¤ì›Œë“œ íŠ¸ë¦¬ê±°(ê°„ë‹¨ ë³„ì¹­ í¬í•¨) â€” í•„ìš”ì‹œ í™•ì¥
_AE_TRIGGER_ALIASES = {
    "QT ì—°ì¥": ["QT", "QTc", "QT prolong", "torsade"],
    "ì†ë°œì¦í›„êµ°": ["hand-foot", "PPE"],
    "RA ì¦í›„êµ°": ["RA syndrome", "retinoic acid"],
}

def _term_present_in_text(term: str, text: str) -> bool:
    if not term:
        return False
    t = (term or "").strip().lower()
    body = (text or "").lower()
    if not body:
        return False
    # 1) ì •ê·œí™”ëœ í‚¤
    k = _to_glossary_key(term)
    if k and k.lower() in body:
        return True
    # 2) ë³„ì¹­
    aliases = _AE_TRIGGER_ALIASES.get(k or term, [])
    for a in aliases:
        if a.lower() in body:
            return True
    # 3) ì›ë¬¸ term ìì²´
    if t and t in body:
        return True
    return False

# build/ë Œë” ê³¼ì •ì—ì„œ ë§ˆì§€ë§‰ MDë¥¼ ì €ì¥í•´ augmentê°€ contextë¥¼ ì°¸ê³ í•˜ë„ë¡ í•¨
_AE_LAST_CONTEXT_MD = ""

def _set_ae_context_md(md_text: str):
    global _AE_LAST_CONTEXT_MD
    _AE_LAST_CONTEXT_MD = md_text or ""

# ê¸°ì¡´ í—¬í¼ë¥¼ 'ë“±ì¥ ì‹œì—ë§Œ ì„¤ëª…'ìœ¼ë¡œ êµì²´
def _augment_terms_with_explain(terms):
    out = []
    mode = (_AE_GLOSSARY_TRIGGER_MODE or "presence_only").lower()
    ctx = _AE_LAST_CONTEXT_MD
    for t in (terms or []):
        label = _norm_ae_term(t)
        exp = _get_explain(t, "short") if mode == "always" else ( _get_explain(t, "short") if _term_present_in_text(t, ctx or label) else None )
        out.append(f"{label} â€” {exp}" if exp else label)
    return out

# render/buildì—ì„œ context ì„¸íŒ…: build_ae_summary_md ëì—ì„œ ì„¸íŒ…í•˜ê³  ë°˜í™˜
__ORIG_build_ae_summary_md = build_ae_summary_md
def build_ae_summary_md(*args, **kwargs):
    md = __ORIG_build_ae_summary_md(*args, **kwargs)
    try:
        _set_ae_context_md(md)
    except Exception:
        pass
    return md

# append_glossary_notesëŠ” presence_onlyì¼ ë•Œ ì´ë¯¸ ë³¸ë¬¸ì— ë“±ì¥í•œ ìš©ì–´ë§Œ ì¶”ê°€(ê¸°ë³¸ ë™ì‘ ìœ ì§€)
# === [PATCH:AE_GLOSSARY_TRIGGERED] END ===

